# Optiverコンペ上位解法から学ぶシステムトレード戦略への応用

## 1. コンペティションの概要

Kaggle「Optiver - Trading at the Close」は、NASDAQ市場のクロージング・クロス（大引けオークション）直前の**10分間**における株価変動を予測するコンペティションである。[^1][^2][^3]

- **データ**: 200銘柄 × 481日分、需給（Bid/Ask）・価格・出来高など17列の板情報[^3]
- **ターゲット**: 60秒後のスペシフィックリターン（個別銘柄リターン − 加重平均リターン）[^3]
- **評価指標**: MAE（平均絶対誤差）[^1][^3]
- **特徴**: ターゲットの分布は裾が広く、極端な値を含む。インバランス系の特徴量がターゲットと高い相関を示した[^4]

マケデコ勉強会（2024年5月23日開催）では、西本氏（データ基礎解析＋1位解法分析）、tonic氏（89位・銀メダル解法）、richwomanbtc氏（上位解法モデル比較）の3名が発表を行った。[^4]

***

## 2. 上位解法の共通パターン

上位解法には以下の共通要素が存在した。[^2][^4]

| 要素 | 内容 | 採用例 |
|---|---|---|
| **GBDTとNNのアンサンブル** | 決定木系モデルとニューラルネットの組み合わせ | 1位: CatBoost+GRU+Transformer、89位: LightGBM+Transformer |
| **オンライン学習** | 評価期間中のデータで定期的にモデルを再学習 | 1位: 12日ごとに再学習 |
| **時間帯グループ化特徴量** | 秒数を区分し、区分内での統計量を特徴量化 | 1位: 0-300秒/300-480秒/480秒以上の3群 |
| **ポストプロセッシング** | 予測値の合計を0に補正（マーケットニュートラル化） | 1位、9位 |

***

## 3. 特徴量エンジニアリング ― システムトレードへの応用

### 3-1. インバランス特徴量の有効性

コンペで最も重要だったのは**需給インバランス系の特徴量**であった。具体的には以下が高い予測力を持つ。[^3][^4]

- **liquidity_imbalance** = (bid_size − ask_size) / (bid_size + ask_size)
- **market_urgency** = (ask_price − bid_price) × liquidity_imbalance
- **size_imbalance** = bid_size / ask_size

これらはピアソン相関係数0.10超とかなり高い相関を示した。学術研究でも、板のインバランスは短期的な価格変動の強力な予測因子であり、特にHFT環境下でその有効性が確認されている。[^5][^6][^3]

**▶ システムトレードへの応用:**
リアルタイムの板情報から、bid/askのサイズ比やインバランス指標を計算し、短期的な方向性シグナルとして活用できる。特にスキャルピングやマーケットメイキング戦略において、エントリー/エグジットのタイミング判断に直結する。

### 3-2. 時間帯グループ化（Magic Features）

1位解法のHYD氏が用いた「Magic Features」は、コンペ最大の差別化要因であった。[^4][^3]

**グループ化の軸:**

1. **時間内グループ化（同一銘柄・秒群間）**: 0-300秒/300-480秒/480秒以上の3つのグループに分割し、各グループ内で「初期値との比率」「移動平均との比率」を算出[^3]
2. **クロスセクショナルグループ化（同一秒・銘柄間）**: 同一タイムスタンプ内の全銘柄について「平均値との比率」「ランクの百分位数」を算出[^3]

この分割は、大引けオークションにおけるmatched/unmatched sizeやbid/ask sizeの挙動が時間帯によって大きく異なることに基づいている。[^3]

**▶ システムトレードへの応用:**
市場のセッション内における時間帯別の挙動パターン（例：前場寄付き直後、昼休み前、大引け前など）を認識し、**時間帯ごとに異なるモデルやパラメータを適用する**設計が有効。また、同一時刻における銘柄間の相対的な位置づけ（ランク・偏差）を特徴量として取り込むことで、セクターローテーションやペアトレード戦略のシグナル精度を向上できる。

### 3-3. ラグ・累積・統計集約特徴量

7位解法ベースの特徴量体系は以下の階層構造を持つ。[^2]

- **生特徴量**: 元データそのまま
- **ベース特徴量**: spread、volume、imbalance_ratio等の基本指標
- **ラグ特徴量**: 過去値（shift/diff/pct_change）
- **累積特徴量**: 各種サイズ・インバランスのrolling集約
- **中央値乖離特徴量**: date_id × seconds_in_bucketでグループ化し、中央値からの乖離
- **Global features**: stock_idごとの統計量（median, std, ptp等）

**▶ システムトレードへの応用:**
特徴量設計は「シンプルなものの組み合わせ」が最も効果的であった。複雑な指標よりも、基本的なspread・volume・imbalanceから派生する特徴量を体系的に生成し、モデルに選択させるアプローチが実運用でも再現性が高い。

***

## 4. モデル選択とアンサンブル戦略

### 4-1. GBDT vs NN の性能比較

richwomanbtc氏の再現実験結果は以下の通り。[^2]

| モデル | スコア | スコア(PP適用後) |
|---|---|---|
| LightGBM | 5.83807 | 5.83807 |
| XGBoost | 5.84004 | 5.84004 |
| CatBoost | 5.85796 | 5.85791 |
| CNN | 5.86448 | - |
| GRU | 5.86424 | - |
| LSTM | 5.86781 | - |
| Transformer | 5.87409 | - |

**単体ではLightGBMが最も高精度**であり、GBDT系がNNよりも扱いやすく精度が出やすい傾向が確認された。[^2][^4]

### 4-2. アンサンブルの威力

ただし、上位解法ではGBDTとNNの**アンサンブルが必須**であった。[^4]

- **1位**: CatBoost(0.5) + GRU(0.3) + Transformer(0.2)[^2][^3]
- **89位（tonic氏）**: LightGBM(0.61) + Transformer(0.39)[^1]
- **実験**: LGB×0.6 + XGB×0.3 + CAT×0.1 → スコア5.83871（わずかに改善）[^2]

tonic氏の分析では、LightGBMとTransformerの予測値の散布図が**かなり異なる傾向**を示しており、予測特性の多様性がアンサンブル効果の源泉であった。[^1]

**▶ システムトレードへの応用:**
- GBDTは欠損値に強く、特徴量の重要度が解釈しやすいため**メインモデル**として適する
- NNは銘柄間のクロスセクショナルな関係性（Transformer）や時系列の依存構造（GRU/LSTM）を捉えるため**補助モデル**として有効
- 実運用ではGBDT：NN = 6：4程度のブレンドが安定的[^1]
- 学術研究でもGBDT＋LSTM等のハイブリッドアンサンブルが単体モデルに対し10-15%の精度改善を達成している[^7]

### 4-3. Transformerの活用方法

tonic氏は**スペシフィックリターン予測のためにTransformer Encoder**を使用した。全銘柄の情報をまとめて入力し、Attention機構で銘柄間の関連性を学習させるアプローチである。[^1]

1位のHYD氏はGRUで**時系列方向**の情報を、Transformerで**銘柄間（クロスセクショナル）方向**の情報を学習させる役割分担を行っていた。[^3]

**▶ システムトレードへの応用:**
複数銘柄を同時に予測するポートフォリオ戦略（ロング・ショート戦略等）では、Transformerの**Self-Attention機構**が銘柄間の相互依存関係を自動的に学習する点が強力。セクター間のシフトや相関変動を動的に捉えることが期待できる。

***

## 5. オンライン学習（Adaptive Learning）

### 5-1. なぜオンライン学習が必要だったか

西本氏の分析により、相関係数がdate_idの進行とともに**低下する傾向**が確認された。つまり、学習データの古い期間の特徴量はターゲットとの相関が徐々に弱まっていく（ドメインシフト）。[^3]

tonic氏も最大の敗因として**オンライン学習の欠如**を挙げており、学習データとテストデータの乖離に対応しきれなかったと分析している。[^4][^1]

### 5-2. 1位解法の実装

1位のHYD氏は**12日ごと（計5回）にモデルを追加学習**させた。これにより、評価期間中の市場レジームの変化に適応できた。[^4][^3]

**▶ システムトレードへの応用:**
金融市場は非定常であり、特徴量とリターンの関係は時間とともに変化する。実運用では以下のアプローチが有効：[^8][^9]

1. **定期再学習**: 一定間隔（1-2週間ごと）でモデルを最新データで再学習
2. **直近データへの重み付け**: 9位解法のように最新45日間のデータに1.5倍の重みを設定する手法[^2]
3. **レジーム検知**: 相関係数やモデル精度のモニタリングにより、再学習タイミングを動的に判断
4. **ウォームスタート**: 既存モデルのパラメータを初期値として追加学習（CatBoost/LightGBMで容易に実装可能）

***

## 6. ポストプロセッシング ― マーケットニュートラル補正

### 6-1. 予測値の合計を0にする補正

1位解法のポストプロセッシングは以下のロジック。[^2]

```
prediction["target"] = (
    prediction["target"]
    - (prediction["target"] * prediction["stock_weights"]).sum()
    / prediction["stock_weights"].sum()
)
```

これは、全銘柄の加重予測値の合計がゼロになるように補正する処理である。スペシフィックリターンの定義上、市場全体のリターンを差し引いた残差を予測しているため、合計がゼロであるべきという問題の構造を反映している。[^4][^2]

**▶ システムトレードへの応用:**
- **マーケットニュートラル戦略**では、ロング・ショートのポジションが市場リスクを打ち消すように構成する必要がある。予測値の合計をゼロに補正するロジックは、ポートフォリオ構築時のドルニュートラル/ベータニュートラル制約と直接対応する。[^10][^11]
- 予測値をそのまま使うのではなく、**市場全体の方向性バイアスを除去した上で銘柄選択に使う**という発想は、ファクター投資やスタットアーブ戦略の基本原則と一致する。

***

## 7. 交差検証（CV）の設計

### 7-1. 時系列分割の重要性

richwomanbtc氏の考察によれば、**単純な時間による2分割CV**（400日train/81日valid）で十分であった。5分割のKFoldはLB（リーダーボード）との相関があまりなさそうであった。[^2]

tonic氏は8Fold CVを採用し、MAEとCV間の安定性（stable_loss）をモニタリングしていた。[^1]

**▶ システムトレードへの応用:**
- 金融時系列では**ルックアヘッドバイアス**を避けるため、時系列ベースの分割が必須[^12]
- 実運用では**ウォークフォワード検証**（学習→検証→学習期間をスライド）が最も信頼性が高い
- LB（実環境）との相関が高いCV設計を最初に見つけることが、以降の実験の信頼性を左右する[^2]
- CVの安定性（分散が小さいこと）は、実運用での**ロバスト性**の代理指標として有用

***

## 8. 失敗から学ぶ ― 効かなかった手法

以下のアプローチは効果がなかった。[^1]

| 失敗した手法 | 理由 |
|---|---|
| **2-stage予測（符号＋絶対値分離）** | LightGBMと予測傾向が似通い、アンサンブルに寄与せず |
| **Rank Gauss変換** | アンサンブルに寄与せず |
| **ボラティリティ予測による補正** | 効果なし |

**▶ システムトレードへの応用:**
- 予測を分解する手法は、**分解の各ステージが十分に異なる情報を捉える場合**にのみ有効
- アンサンブルの効果は「予測特性の多様性」に依存するため、似た手法を複数組み合わせても効果は限定的
- ボラティリティ予測による補正が効かなかった点は、**ボラティリティ自体の予測が難しい**ことを示唆しており、実運用でもボラティリティのレジームに応じたポジションサイジングの方が、予測値補正よりも実用的

***

## 9. 実運用への統合 ― システムトレード戦略設計の指針

上記の学びを統合すると、以下のシステムトレード戦略フレームワークが導かれる。

### Phase 1: データ基盤とパイプライン構築
- tonic氏のように「前処理→特徴量計算→学習→予測→後処理→評価」の**パイプラインをパッケージ化**する[^1]
- 実験の高速化・正確性が後続の試行錯誤の質を決定する

### Phase 2: 特徴量設計
- 板情報からインバランス系特徴量を体系的に生成
- 時間帯グループ化により市場マイクロストラクチャの構造を反映
- 銘柄間のクロスセクショナル特徴量（ランク、平均乖離）を追加
- Global features（銘柄ごとの統計量）でコンテキストを付与

### Phase 3: モデル構築
- **メインモデル**: LightGBM（高精度・高速・欠損値に強い）
- **補助モデル**: Transformer（銘柄間関係）+ GRU/LSTM（時系列依存）
- **アンサンブル**: OOF最適化でブレンド比率を決定（GBDT:NN ≈ 6:4が目安）

### Phase 4: 運用・適応
- **定期再学習**（1-2週間サイクル）による市場レジーム変化への適応
- 直近データへの重み付けによるドメインシフト軽減
- 予測値のマーケットニュートラル補正（ロング・ショート制約の適用）

### Phase 5: 監視・改善
- CV安定性と実運用パフォーマンスの乖離をモニタリング
- Feature importanceの時間推移を追跡し、特徴量の陳腐化を検知
- 相関係数の推移からオンライン学習の頻度を動的に調整

***

## 10. まとめ ― 核心的な学び

このコンペティションから得られる、システムトレードに直結する核心的な学びは以下の5点である。

1. **「特徴量がすべて」である**: モデルの精度改善は、アーキテクチャの工夫よりも、問題の構造を反映した特徴量設計によるところが大きい[^12][^4]
2. **市場は非定常であり、適応が必須**: オンライン学習の有無が上位と中位を分ける最大の要因であった[^4][^1]
3. **予測特性の多様性がアンサンブルの価値を生む**: GBDTとNNの組み合わせは、単なる精度向上ではなく、異なる視点からの予測が安定性をもたらす[^1][^2]
4. **ポストプロセッシングは戦略の一部**: 予測値の補正（ニュートラル化）は、問題の数学的構造を活かしたリスク管理手法として実運用に直結する[^4][^2]
5. **信頼できるCVの設計が全ての基盤**: 実験の方向性を正しく導くCV設計なくして、特徴量もモデルも意味をなさない[^1][^2]

---

---

## 付録A. 勉強会 議事録（原文）

> 以下は2024年5月23日マケデコ勉強会の議事録原文。本ドキュメントの各セクションはこの議事録と
> 3つの発表PDF（docswell-K6YQ3E.pdf、Optiver参戦記_銀メダル解法.pdf、makedeco-optiver-main/slide/）を
> 統合・分析して作成されている。

マケデコ「Optiverコンペ Kaggle上位解法勉強会」議事録

**開催日時**: 2024年5月23日 19:30〜 **主催**: マケデコ (Market API Developer Community) **司会**: 北山氏

1. 概要

Kaggleで開催されたコンペティション「Optiver - Trading at the Close」の上位解法および参加者による振り返りを共有する勉強会。Nasdaqのクロージング・クロス（大引け）直前の10分間における株価変動を予測する課題に対し、データの基礎解析、銀メダル獲得解法、および上位解法の比較分析が発表された。

\--------------------------------------------------------------------------------

2. 発表内容

(1) データの基礎解析 ＋ 1st Solution 解法共有

**発表者**: 西本氏（nishimoto）

• **コンペ概要とデータ解析**:

  ◦ **課題**: 米国株式市場の終了直前10分間のボラティリティと価格変動を予測する。評価指標はMAE。

  ◦ **データ**: 200銘柄 × 481日分。需給（Bid/Ask）、価格、出来高など17列の基本データが提供された。

  ◦ **特徴**: ターゲット（目的変数）の分布は裾が広く、極端な値が含まれる。また、インバランス（需給の偏り）系の特徴量がターゲットと高い相関を示した。

• **1位解法（HYD氏）の分析**:

  ◦ **モデル構成**: **CatBoost (0.5) + GRU (0.3) + Transformer (0.2)** のアンサンブル。GBDT（決定木）とNN（ニューラルネット）を組み合わせている。

  ◦ **勝因（Magic Features）**: 特定の時間帯（0-300秒、300-480秒、480秒以降）でグループ化し、その中での「初期値との比率」や「移動平均との比率」をとる特徴量が有効であった。

  ◦ **オンライン学習**: 評価期間中に追加されるデータを使ってモデルを再学習（12日ごと）させたことがスコア向上に大きく寄与した。

(2) Optiver参戦記 & 銀メダル解法

**発表者**: tonic氏（89位 / 銀メダル）

• **解法アプローチ**:

  ◦ **モデル**: **LightGBM (0.61) + Transformer (0.39)** のアンサンブル。

  ◦ **特徴量**: 462個の特徴量を作成。各ペアの乖離、インバランス、日内のローリング集約、データセット全体でのグループエンコーディングなどを採用。

  ◦ **Transformerの活用**: 銘柄間の相関（Cross-sectional）を捉えるためにTransformer Encoderを使用。GBDTとは異なる予測特性を持ち、アンサンブルでの寄与度が大きかった（重み約4割）。

• **反省点・上位との差分**:

  ◦ **オンライン学習の欠如**: 計算リソースと時間の制約から再学習を実装できず、ドメインシフト（学習データとテストデータの乖離）に対応しきれなかった点が最大の敗因と分析。

  ◦ **時系列ベクトルの扱い**: GRUやCNNなど、時系列方向の情報をうまく扱うモデルの検討が不足していた。

  ◦ **失敗した試行**: ターゲットを符号と絶対値に分けて予測する2-stage予測や、ボラティリティ予測による補正は効果がなかった。

(3) 上位解法モデル比較

**発表者**: richwomanbtc氏（1836位）

• **上位解法の傾向分析**:

  ◦ 上位陣は共通して「Treeモデル（GBDT）と時系列NNのアンサンブル」「オンライン学習」「時間枠でグループ化した特徴量」「ポストプロセッシング（予測値の合計を0にする等の補正）」を採用していた。

  ◦ 6位はNN単独、9位はXGBoost単独など、バリエーションも存在した。

• **再現実験と考察**:

  ◦ 7位解法をベースに、同一の特徴量を用いて複数モデル（LightGBM, CatBoost, CNN, GRU, LSTM, Transformer）の性能を比較検証。

  ◦ **結果**: 単体モデルではLightGBMが最も精度が高かった。NNモデル群（CNN, LSTM等）も健闘したが、GBDT系の方が扱いやすく精度が出やすい傾向が見られた。

  ◦ **特徴量の重要性**: 「時間帯ごとのグループ化」や「中央値からの乖離」といった、市場構造を反映した特徴量が有効であった。

\--------------------------------------------------------------------------------

3. 質疑応答・主な議論

• **オンライン学習への気づき**: データIDごとの相関係数の推移を見ると、古いデータほど相関が弱くなっている傾向があったため、そこから直近データを重視する（オンライン学習）必要性に気づけた可能性がある。

• **Transformerの欠損値処理**: ファープライス（Far Price）などが前半欠損する場合、定数（1など）で埋める処理が行われていた。

• **モデルの選択**: 最終的にはLightGBMなどのGBDTが強力だが、予測特性の異なるNN（Transformerなど）をアンサンブルに混ぜることでスコアが安定・向上する点が確認された。

4. 所感・まとめ

• 本コンペティションは「シェイク（順位変動）」が少なく、適切なデータ分析とエンジニアリング（特にオンライン学習と特徴量作成）を行った参加者が報われるロバストな設計であった。

• 上位に入るには、GBDTだけでなくNNを含めた多様なモデルのアンサンブルと、計算コストのかかるオンライン学習を実装しきるエンジニアリング力が求められた。

---

## 参考資料

### ローカルファイル（本リポジトリ内）
- [^1]: `Optiver参戦記_銀メダル解法.pdf` — tonic氏（89位・銀メダル）の発表スライド
- [^2]: `makedeco-optiver-main/slide/slide.md` — richwomanbtc氏の上位解法まとめスライド
- [^3]: `docswell-K6YQ3E.pdf` — 西本氏のデータ基礎解析＋1位解法分析スライド
- [^4]: 勉強会議事録（本ドキュメント付録Aに統合済み）

### Kaggle Discussion（外部リンク）
- [^5]: [Leveraging Limit Order Book Imbalances for Profitable Trading](https://electronictradinghub.com/leveraging-limit-order-book-imbalances-for-profitable-trading-a-deep-dive-into-recent-research-and-practical-tools/)
- [^6]: [Impact of HFT with Order Book Imbalance](https://onlinelibrary.wiley.com/doi/10.1155/2023/3996948)
- [^7]: [Gradient Boosting Decision Tree with LSTM for Investment](https://arxiv.org/html/2505.23084v1)
- [^8]: [Machine Learning in Financial Markets](https://www.subex.com/blog/machine-learning-in-financial-markets-applications-effectiveness-and-limitations/)
- [^9]: [Online Adaptive ML for Implied Volatility](https://arxiv.org/pdf/1706.01833.pdf)
- [^10]: [Market Neutral Strategies](https://hedgenordic.com/wp-content/uploads/2015/12/MarketNeutralReport_2015-1.pdf)
- [^11]: [Market Neutral Strategy](https://www.wallstreetprep.com/knowledge/market-neutral-strategy/)
- [^12]: [Optiver Trading at the Close - GitHub](https://github.com/liyiyan128/optiver-trading-at-the-close)

### Kaggle上位解法 Discussion
- 1st place: https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/487446
- 6th place: https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/486040
- 7th place: https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/486157
- 9th place: https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/486237

> **注記**: 本ドキュメントはPerplexityによって生成され、上記の発表資料と議事録を統合・分析したものである。
> 参照番号 [^1]～[^12] は元のPerplexity出力に基づく。S3一時URLは永続的なローカルファイル参照に置換済み。
